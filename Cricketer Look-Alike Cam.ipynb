{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e060945",
   "metadata": {},
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d50fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d996902",
   "metadata": {},
   "source": [
    "# Loading the Model Weights and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c467e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "json_file = open('model_arch.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0794d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recogniser = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246c0f8",
   "metadata": {},
   "source": [
    "# Creating the Dataset of Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size = (160, 160))\n",
    "    img = np.around(np.array(img) / 255.0, decimals = 12)\n",
    "    x_train = np.expand_dims(img, axis = 0)\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding / np.linalg.norm(embedding, ord = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"cricketer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "for i in os.listdir():\n",
    "    if i != \".DS_Store\":\n",
    "        j = i.split(\".\")[0].title()\n",
    "        database[j] = img_to_encoding(i, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82a418",
   "metadata": {},
   "source": [
    "# Input - Face Detection + Look-Alike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea06f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_is_it(image_path, database, model):\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    min_dist = 1e6\n",
    "    \n",
    "    for (name, enc) in database.items():\n",
    "        dist = np.linalg.norm(encoding - enc)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"It's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a26446",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"\") # Enter image path \n",
    "gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62872b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "face = face_classifier.detectMultiScale(gray_image, scaleFactor = 1.1, minNeighbors = 5, minSize = (40, 40))\n",
    "\n",
    "for (x, y, w, h) in face:\n",
    "    cv.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "    \n",
    "faces = img[y + 3 : y + h - 2, x + 3 : x + w - 2]\n",
    "img_rgb = cv.cvtColor(faces, cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"face.png\"\n",
    "cv.imwrite(path, img_rgb)\n",
    "who_is_it(path, database, face_recogniser)\n",
    "os.remove(\"face.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
